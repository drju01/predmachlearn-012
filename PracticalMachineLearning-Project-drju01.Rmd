---
title: "Practical Machine Learning - Project"
author: "drju01"
date: "Sunday, March 22, 2015"
output: html_document
---
Executive Summary:

The following project assignment explores "Weight Lifting Exercises Dataset" that contains information on how well a weight lifting activity was performed by the study participant. Six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E). Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes. The objective of the assignment is to use the provided training dataset to fit a model that will be used to predict outcome of 20 test cases.

1) First, datasets were loaded ("NA" values defined appropriately)
```{r, echo=FALSE, warning=FALSE}
library(caret)
setwd("E:/Coursera - Practical Machine Learning")
```
```{r}
training = read.csv("pml-training.csv", na.strings=c("NA","#DIV/0!",""))
testing = read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!",""))
```

2) Next, the training dataset was partitioned into train and validation data sets 
```{r}
set.seed(32343)
inTrain <- createDataPartition(y=training$classe, p=0.20, list=FALSE)
trainSet <- training[inTrain,]
validSet <- training[-inTrain,]
```

3) After initial exploration it was determined that some columns were mostly filled with NA values (over 50% of all values), bringing no information and only creating noise. Those columns were removed from the train dataset.
```{r}
checkNA <- apply(is.na(trainSet),2,sum)
trainSetNN <- trainSet[, checkNA/nrow(trainSet) < 0.5]
length(trainSetNN[1,])
```

4) In addition, columns that were irrelevant given the dataset context (ie. evaluation of how well excercise is performed) were be removed. Thus, columns like user_name, timestamps, new_window, etc. were purged.
```{r}
trainSetClean <- trainSetNN[,c(8:60)]
length(trainSetClean[1,])
```

5) In order to further reduce dimensionality, highly correlated variables were removed.
```{r}
trainSetCor <- cor(trainSetClean[,-53])
highlyCor <- findCorrelation(trainSetCor, cutoff = .75)
trainSetUncor <- trainSetNN[,-highlyCor]
length(trainSetUncor[1,])
```

6) Subsequently, 10-fold cross-validation was configured for model training. 
```{r, echo=FALSE, warning=FALSE}
library("parallel")
library("doParallel")
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl, cores = detectCores() - 1)
```
```{r}
fitControl <- trainControl(method="cv",number=10,allowParallel=TRUE)
```

7) The selected training method was "Random Forest" as it provided very good accuracy and prediction performance compared to other algorithms. Over 98% Accuracy and unweighted Kappa metrics for the generated model (when using 30 variables available for splitting at each tree node,ie. mtry) confirmed that the model fitted training data very well.
```{r}
rndforstFit <- train( classe ~ ., data=trainSetUncor, method="rf", prox=TRUE, trControl=fitControl )
```
```{r}
rndforstFit
```
```{r, echo=FALSE, warning=FALSE}
stopCluster(cl)
```

8) The fitted model was validated by applying it to validation dataset. Obtained Accuracy was again over 98%, meaning out-of-sample error was less than 2% (which is very similar to the in-sample error).
```{r}
confusionMatrix(validSet$classe, predict(rndforstFit, validSet))
```

9) Finally, the fitted model was applied to the test dataset to predict the "classe" response for 20 test cases. 
```{r}
predict(rndforstFit, testing)    
```